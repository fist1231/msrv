docker:
=======
###########################################################################################################################################################

$ docker network ls
$ docker run --network=<NETWORK>
$ docker network inspect bridge

$ docker network create -d bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 dockernet
$ docker network rm dockernet

$ docker network create -d bridge --subnet 172.17.0.0/24 --gateway 172.17.0.1 dockernet

$ docker attach container1

docker info

You can share a drive “on demand” the first time a particular mount is requested:

docker --rm -v c:/Users:/data ls /data run hello-world
docker run hello-world

docker run  -it ubuntu bash | exit

docker run -d -p 80:80 --name webserver nginx
192.168.99.100
docker ps
docker stop webserver
docker start webserver
docker rmi nginx

~~~~~~~~~~~~~~~~~~~~~~

Windows Power Shell run as admin
Set-ExecutionPolicy RemoteSigned
Install-Module posh-docker
Import-Module posh-docker

if (-Not (Test-Path $PROFILE)) {
    New-Item $PROFILE –Type File –Force
}

Add-Content $PROFILE "`nImport-Module posh-docker"

This creates a $PROFILE if one does not already exist, and adds this line into the file:
Import-Module posh-docker
To check that the file was properly created, or simply edit it manually, type this in PowerShell:
Notepad $PROFILE

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



docker run --rm -v c:/Users:/data ls /data -i -t -p 3333:3333 --network="host" users-node:v1 /bin/bash

===============
Local Registry:
===============

docker run -d -p 5000:5000 --restart=always --name registry registry:2

docker pull ubuntu:16.04
docker tag ubuntu:16.04 localhost:5000/my-ubuntu

Push the image to the local registry running at localhost:5000:
docker push localhost:5000/my-ubuntu

Remove the locally-cached ubuntu:16.04 and localhost:5000/my-ubuntu images, so that you can test pulling the image from your registry. This does not remove the localhost:5000/my-ubuntu image from your registry.

docker image remove ubuntu:16.04
docker image remove localhost:5000/my-ubuntu

Pull the localhost:5000/my-ubuntu image from your local registry.

======================
Stop a local registry:
======================

docker stop registry

To remove the container, use docker rm
docker stop registry && docker rm -v registry
docker rmi -f registry
docker rmi -f registry:2



###########################################################################################################################################################

-create server.js
-create Dockerfile
docker build -t n1-node:v1 .




docker images
docker ps
192.168.99.100

docker build -t hello-node:v1 .

docker run -i -t -p 8080:8080 hello-node:v1 /bin/bash

2. another node
docker build -t bcx-node:v1 .
docker run -i -t -p 5555:5555 bcx-node:v1 /bin/bash


docker registry in docker:
=========================

docker run -d -p 5000:5000 --name registry registry:2
docker pull ubuntu
docker tag ubuntu localhost:5000/myfirstimage
docker push localhost:5000/myfirstimage
docker pull localhost:5000/myfirstimage
docker stop registry && docker rm -v registry


docker tag ubuntu localhost:5000/n1-node:v1
docker push localhost:5000/n1-node:v1
docker pull localhost:5000/n1-node:v1


minikube:
========

start minikube:
==============
minikube status

minikube stop
minikube start --vm-driver="virtualbox"

minikube start --vm-driver="virtualbox" --insecure-registry="0.0.0.0:5000"
kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100

create deployment:

kubectl delete deployment n1-node
kubectl run n1-node --image=n1-node:v1 --port=8080




kubectl get pod
kubectl get deployments

create service:

-expose
kubectl expose deployment n1-node --type=LoadBalancer
kubectl get services

-start service:
minikube service n1-node

http://192.168.99.101:31528/


CLUSTER IP:
===========
kubectl run n1-5-node --replicas=5 --labels="run=load-balancer-example" --image=n1-node:v1  --port=8080
-kubectl get deployments n1-5-node
-kubectl describe deployments n1-5-node
-kubectl get replicasets
-kubectl describe replicasets

//kubectl expose deployment n1-5-node --type=LoadBalancer --name=n1-5-service    not working on single minikube
kubectl expose deployment n1-5-node --type=NodePort --name=n1-5-service
-kubectl get services n1-5-service
-kubectl describe services n1-5-service

minikube service n1-5-service

kubectl delete services n1-5-service
kubectl delete deployment n1-5-node


==============================================================================================================================

Docker image users.js:
======================
1. docker quickstart shortcut
2. cd c:/angular/msrv/services/nress/users
3. docker build -t users-node:v1 .
4. docker images
docker ps

5. Test: 
# docker run -i -t -p 3333:3333 users-node:v1 /bin/bash
docker run -i -t -p 3333:3333 --network=host users-node:v1 /bin/bash

remove image
docker rmi -f users-node:v1


$ ip addr show eth0


dockerfile from:
===============
FROM node:8.9.1
EXPOSE 3333
COPY ./ .
CMD node users.js

to:
===


RUN npm install -g nodemon
COPY ./script.js /root/script.js
CMD ["nodemon", "-w", "./users.js", "./users.js"]


Move to registry (drop/re-create registry first):
================================================

#docker run -v $(pwd)/data:/tmp/registry-dev --name docker-registry registry:2.0

#docker run -p 443:443 -e REGISTRY_HOST="docker-registry" -e REGISTRY_PORT="5000" -e SERVER_NAME="localhost" --link docker-registry:docker-registry 


docker stop registry && docker rm -v registry
docker run -d -p 5000:5000 --name registry registry:2

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
~~~~~~~~~~~~~~~~~~~~~
Build from Dokerfile:
~~~~~~~~~~~~~~~~~~~~~
1. Build:
$ docker build -t users-node:v1 .
$ docker images

2. Test:
$ do
# nodemon -w ./users.js ./users.js
http://192.168.99.100:3333/nress/users

2. Create Registry, if not present (delete old ones):

docker stop registry && docker rm -v registry
docker rmi -f registry
docker rmi -f registry:2

// $ docker run -d -p 5000:5000 --restart=always --name registry registry:2 - https
// $ docker run -d -p 5000:5000 --restart=always --name registry registry
$ docker run -d -p 5000:5000 --network=host --restart=always --name registry registry:2

3. Put to local registry for Kubernetes:
// $ docker tag users-node:v1 localhost:5000/users-node
// $ docker push localhost:5000/users-node
$ docker tag users-node:v1 192.168.99.100:5000/users-node
$ docker push 192.168.99.100:5000/users-node

-Remove old images:
$ docker image remove users-node:v1
or
$ docker rmi -f users-node:v1

$ docker image remove localhost:5000/users-node

-Test pull now from local registry:
// $ docker pull localhost:5000/users-node
$ docker pull 192.168.99.100:5000/users-node

- Test again:
$ docker run -i -t -p 3333:3333 --network=host localhost:5000/users-node /bin/bash
# nodemon -w ./users.js ./users.js
http://192.168.99.100:3333/nress/users

Fin.

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To kubernetes: (start power shell with admin priv)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

1. Exit Docker, if present (shortcut kill). Minikube will start its own.

2. Start minikube (192.168.99.106)
minikube delete

minikube start --insecure-registry "10.0.0.0/24"
#minikube start --vm-driver="virtualbox" - no
#minikube start --vm-driver="virtualbox" --insecure-registry="localhost:5000" - no

minikube start --vm-driver="virtualbox" --insecure-registry="0.0.0.0:5000"
#minikube start --vm-driver="virtualbox" --insecure-registry="192.168.99.100:5000"  - connection refused

~/.minikube/machines/minikube/config.json

minikube status
#kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.103
#kubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.101

kubectl get pod
kubectl get deployments
kubectl delete deployment users-node

#kubectl create secret docker-registry my-secret --docker-server=127.0.0.1:5000
# kubectl create secret docker-registry my-secret --docker-server=127.0.0.1:5000 --docker-username=uname --docker-password=****** --docker-email=email@sample.com

kubectl run users-node --image=localhost:5000/users-node --port=3333
kubectl get pod

kubectl run users-node --replicas=5 --labels="users-node minikube service" --image=localhost:5000/users-node --port=3333

2. kubectl expose deployment users-node --type=NodePort --name=users-service
kubectl delete services/users-service
kubectl delete deployment users-node

3. minikube service users-service

-----------------------------------------------------------------------------------------------------------------------------------------------------------
For Mongo ip access:

ipconfig /all
Ethernet adapter VirtualBox Host-Only Network: IPv4 Address

kubectl get po --all-namespaces
//if no dns module, do these:

minikube stop
PS C:\Program Files\Oracle\VirtualBox> 
.\VBoxManage.exe modifyvm "minikube" --natdnsproxy1 on
.\VBoxManage.exe modifyvm "minikube" --natdnshostresolver1 on

minikube start


minikube start --vm-driver="virtualbox"
minikube docker-env
minikube docker-env | Invoke-Expression
docker images
...

docker build -t users-node:v1 .
kubectl run users-node --replicas=5 --image=users-node:v1 --port=3333

sudo kubectl run users-node --replicas=5 --image=users-node:v1 --port=3333 --env="DOMAIN=cluster"

kubectl get pod

or for own port goto 2:

kubectl expose deployment users-node --type=NodePort --name=users-service
// kubectl expose deployment users-node --type=LoadBalancer --name=users-service
kubectl get service

users-service   NodePort    10.103.136.109   <none>        3333:31367/TCP   12s

http://192.168.99.103:31367/nress/users

kubectl get namespaces
$ curl $(minikube service users-node --url)

kubectl describe services users-service
kubectl cluster-info

2:
==
get yaml:
kubectl edit svc users-service
add nodePort: 31234  (range: The range of valid ports is 30000-32767)

save as users-service.yaml

kubectl delete service users-service

kubectl create -f users-service.yaml




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
====================== Ubuntu 17.04 kubernetes ==================================
1. Install dependency library
sudo apt-get update 
sudo apt-get install -y apt-transport-https

2. Docker:
sudo apt install docker.io

Docker is enabled upon boot:
sudo systemctl enable docker.service

Once that completes, start and enable the Docker service with the commands

sudo systemctl start docker
sudo systemctl enable docker

3. Install Kubernetes:

- Add key for new repository and add repository
sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add 

- creating the file /etc/apt/sources.list.d/kubernetes.list and enter the following content:
deb http://apt.kubernetes.io/ kubernetes-xenial main
Save and close that file. Install Kubernetes with the following commands:

- install kubernetes
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl kubernetes-cni

- Initialize your master
With everything installed, go to the machine that will serve as the Kubernetes master and issue the command:

(sudo kubeadm reset)
sudo swapoff -a
sudo kubeadm init

or

Didn't work:
# echo 'Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"' > /etc/systemd/system/kubelet.service.d/90-local-extras.conf
# systemctl daemon-reload
# systemctl restart kubelet

/healthz: dial tcp 127.0.0.1:10255: getsockopt: connection refused.

sudo ufw status

Didn't work: 
// sudo nano /etc/default/ufw
// DEFAULT_FORWARD_POLICY="DROP"
// to
// DEFAULT_FORWARD_POLICY="ACCEPT"
// sudo ufw reload

Didn't work:
// sudo ufw disable
// sudo ufw enable

sudo kubeadm reset
add "Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"" to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
sudo systemctl daemon-reload
sudo systemctl restart kubelet
sudo kubeadm init --skip-preflight-checks
or kubeadm init --node-name master

//////////////////////////////////////////////////////////////////////////////////
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.8.5
[init] Using Authorization modes: [Node RBAC]
[preflight] Skipping pre-flight checks
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [tsa-ubt kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.208]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
[kubeconfig] Wrote KubeConfig file to disk: "admin.conf"
[kubeconfig] Wrote KubeConfig file to disk: "kubelet.conf"
[kubeconfig] Wrote KubeConfig file to disk: "controller-manager.conf"
[kubeconfig] Wrote KubeConfig file to disk: "scheduler.conf"
[controlplane] Wrote Static Pod manifest for component kube-apiserver to "/etc/kubernetes/manifests/kube-apiserver.yaml"
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to "/etc/kubernetes/manifests/kube-controller-manager.yaml"
[controlplane] Wrote Static Pod manifest for component kube-scheduler to "/etc/kubernetes/manifests/kube-scheduler.yaml"
[etcd] Wrote Static Pod manifest for a local etcd instance to "/etc/kubernetes/manifests/etcd.yaml"
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory "/etc/kubernetes/manifests"
[init] This often takes around a minute; or longer if the control plane images have to be pulled.
[apiclient] All control plane components are healthy after 36.502629 seconds
[uploadconfig]Â Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[markmaster] Will mark node tsa-ubt as master by adding a label and a taint
[markmaster] Master tsa-ubt tainted and labelled with key/value: node-role.kubernetes.io/master=""
[bootstraptoken] Using token: 48fc6f.fd4313ca8539efc7
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: kube-dns
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 48fc6f.fd4313ca8539efc7 192.168.1.208:6443 --discovery-token-ca-cert-hash sha256:4b4027ed823e14f7adf46ec57fd1f731d0485354ee51735ddacb75e319106f6a
/////////////////////////////////////////////////////////////////////////////////

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


6. Deploying a pod network, Flannel

- sudo kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

7. Enable master node run pod [optional]
kubectl taint nodes --all node-role.kubernetes.io/master-

sudo kubectl get pods
kubectl cluster-info
https://192.168.1.208:6443/api/v1/namespaces/kube-system/services/kube-dns/proxy

